<?xml version="1.0" encoding="UTF-8"?>

<section xml:id="sec-2-3-basis-dimension" xmlns:xi="http://www.w3.org/2001/XInclude">
  <title>Basis and Dimension</title>
<p>
<definition xml:id="def-sec2-2-LI"><title>Basis</title>


  <statement>
    <p>
      A set of vectors <m>\beta=\{v_1,v_2,\ldots,v_n\}</m> is called a basis of <m>\R^n</m> if every vector <m>v\in \R^n</m> can be  expressed uniquely as  linear combinations of <m>v_1,v_2,\ldots,v_n</m>. 
	
      Thus <m>\beta</m> is basis of <m>\R^n</m> if 
    <p>(i) <m>L(\beta)=\R^n</m>, that every vector <m>v\in \R^n</m> can be expressed as linear combinations of <m>v_1,v_2,\ldots,v_n</m>. </p>
    <p>	(ii) If <m>v=\alpha_1v_1+\alpha_2v_2+\cdots +\alpha_nv_n</m> and <m>v=\beta_1v_1+\beta_2v_2+\cdots +\beta_nv_n</m>, then <m>\alpha_1=\beta_1, \alpha_2=\beta_2=\cdots,\alpha_n=\beta_n</m>.</p>
    <p>
    Similarly one can define a basis of any subspace of <m>\R^n</m>.</p>     
    </p>
  </statement>
</definition>
</p>

<p>
  It is easy to prove the follwoing theorem which is opent taken as definition in many books.
</p>
<p>
  <theorem xml:id="thm-sec2-3-basis-thm1">
    <statement>
      <p>
        A set of vectors <m>\beta=\{v_1,v_2,\ldots,v_n\}</m> is called a basis of <m>\R^n</m> iff (i) <m>L(\beta)=\R^n</m>and <m>\beta</m> is linearly independent. 
    
      </p>
    </statement>
  </theorem> 
</p>
<p>
  <example>
    <p> (i) <m>\{(1,0),(0,1)\}</m> is a basis of <m>\R^2</m> called the standard basis of <m>\R^2</m>.</p>
    <p>  (ii) <m>\{(1,-1),(2,1)\}</m> is a basis of <m>\R^2</m>.</p>
    <p> (iii) <m>\{(1,0,0),(0,1,0),(0,0,1)\}</m> is a basis of <m>\R^3</m> called the standard basis of <m>\R^3</m>. </p>
    <p> (iv) <m>\{(1,1,-1),(-1,1,1),(1,-1,1)\}</m> is a basis of <m>\R^3</m>. </p>
      
  </example>
</p>
<p>
  In <m>\R^n</m>, we define <m> e_i:=(0,\ldots, 1,\ldots,0)</m> where <m>i</m> component is 1 rest are zeros. Then it is easy to see that <m> \{e_1,\ldots, e_n\}</m> is a bais of  <m>\R^n</m> called the <alert>standard basis</alert>.
</p>
<p>
<example>
  <p>
    Consider the plane <m>W=\{(x_1,x_2,x_3)\in \R^3:x_1+2x_2-x_3=0\}</m>. Note that, here <m>x_1</m> and <m>x_2</m> can be thought of as free variables. Any point <m>(x_1,x_2,x_3)\in W</m>, we have 
<me>(x_1,x_2,x_3)=(x_1,x_2,x_1+2x_2)=(\alpha,\beta,\alpha+2\beta)=\alpha(1,0,1)+\beta(0,1,2).</me>
Thus <m>\{(1,0,1),(0,1,2)\}</m> spans <m>W</m>. It is easy to see that <m>\{(1,0,1),(0,1,2)\}</m> is linearly independent. Hence <m>\beta =\{(1,0,1),(0,1,2)\}</m> is a basis of <m>W</m>. In fact, any two vectors in <m>W</m> which are linearly independent form a basis of <m>W</m>.


  </p>
</example>
</p>
<p>
  <theorem xml:id="thm-sec2-3-thm3">
    <statement>
      <p>
        Any set of <m>n</m> linearly independent vectors forms a basis of <m>\R^n</m>.

      </p>
    </statement>
  </theorem>
  
</p>
<p>
  <proof>
    <p>
      Follows from Theorem <xref ref="thm-sec2-2-thm2"/>.
    </p>
  </proof>
</p>

<p>
  <theorem xml:id="thm-sec2-3-thm4">
    <statement>
      <p>
     Let <m> \beta=\{v_1,v_2,\ldots,v_k\}</m> be a basis of a subscape <m>W</m>  of <m>\R^n</m> with <m>k</m> elements. Then any set 
     <m>S=\{v_1,v_2,\ldots, v_{k+1}\}\subset W</m> with <m>k+1</m> elements is linearly dependent.   
      </p>
    </statement>
  </theorem>
  </p>
 <p>
  <proof>
    <p>
      Let <m>\alpha_1,\ldots,\alpha_{k+1}</m> be scalars such that
      <men xml:id="sec2-3-eq1"> \alpha_1 v_1+\alpha_2v_2+\cdots+\alpha_kv_k+\alpha_{k+1}v_{k+1}=0</men>
      Since <m>\beta</m> is a basis of <m>W</m>, for each <m>i=1,2,\ldots, k+1</m>, we have
      <me> v_i = \sum_{j=1}^k a_{ij}u_j</me>
      Substituting this in Equation <xref ref="sec2-3-eq1"/>, we get
      <men xml:id="sec2-3-eq2">
        \alpha_1 \left(\sum_{j=1}^k a_{1j}u_j\right)+\cdots+
        \alpha_{k+1}\left(\sum_{j=1}^k a_{k+1j}u_j\right)=0
      </men>
      Collecting the coefficients of <m>u_i's</m> in the Equation <xref ref="sec2-3-eq2"/>, we get
    <men xml:id="sec2-3-eq3">
      \left(\sum \alpha_ia_{i1}\right)u_1+\cdots +
      \left(\sum \alpha_ia_{ik+1}\right)u_{k+1}=0.
    </men>
    Since<m>\beta</m> is lineary independent, we have
    <md>
      <mrow>\alpha_1 a_{11}+\alpha_2a_{21}+\cdots+\alpha_{k+1}a_{k+11} =\amp 0 </mrow>
      <mrow>\alpha_1 a_{12}+\alpha_2a_{22}+\cdots+\alpha_{k+1}a_{k+12} =\amp 0 </mrow>
      <mrow>\vdots  \amp  </mrow>
      <mrow>\alpha_1 a_{1k}+\alpha_2a_{2k}+\cdots+\alpha_{k+1}a_{k+1k} =\amp 0 </mrow>
    </md>
    </p>
    These are <m>k</m> homogeneous linear equations in <m>k+1</m> variables <m>\alpha_1,\ldots,\alpha_{k+1}</m>. 
      Hence it has a non zero solution. In particular, there exist scalars,  <m>\alpha_1,\ldots,\alpha_{k+1}</m> not all zero such that <m>\alpha_1 v_1+\alpha_2v_2+\cdots+\alpha_kv_k+\alpha_{k+1}v_{k+1}=0</m>. Hence <m>S</m> is linearly dependent.
  </proof>
</p>
  
<corollary xml:id="sec2-3-cor1">
  <statement>
    <p>
      Let <m> \beta=\{v_1,v_2,\ldots,v_k\}</m> be a basis of a subscape <m>W</m>  of <m>\R^n</m> with <m>k</m> elements. If <m>S</m> is a linearly independet subset in <m>W</m>, then <m>|S|\leq k</m>. 
    </p>
  </statement>
</corollary>
<p>
  <theorem xml:id="thm-sec2-3-thm5">
    <statement>
      <p>
        Let <m>\beta</m> and <m>\gamma</m> be two bases of  a subscape <m>W</m>  of <m>\R^n</m>. Then <m>\beta</m> and <m>\gamma</m> have the same number of elements. 
      </p>
    </statement>
  </theorem>
  </p>
  <p>
  <proof>
    <p>
      Suppose <m>|\beta|=r</m> and <m>|\gamma|=s</m>.  Since <m>\beta</m> is a basis and <m>\gamma</m> is linearly independet, by Corollary <xref ref="sec2-3-cor1"/>, <m>s\leq r</m>. Similarly <m>\gamma</m> is a basis and <m>\beta</m> is linearly independet, we have <m>s\leq r</m>. Hence <m>r=s</m>.
    </p>
  </proof>
</p>
Since the number of elements any two bases are same. This leads to the dinition of dimension of a vector subspace.

<p>
  <definition xml:id="def-sec2-3-dimension">
    <statement>
      <p>
        Let <m>W</m> be subspace of <m>\R^n</m>. The number of elements in a basis of <m>W</m> is called the <alert>dimension</alert> of <m>W</m>. 	
 
      </p>
    </statement>
  </definition>
</p>
<p>
  <example>
    <p>(i) <m>\R^n</m> is a <m>n</m>-dimensional vector space over <m>\R</m>.</p>
<p>(ii) Any plane passing through origin in <m>\R^3</m> is a 2 dimensional subspace.</p>
<p>(iii) <m>W:=\{(x_1,\ldots,x_n):x_1+\cdots+x_n=0\}</m> is <m>n-1</m> dimensional subspace of <m>\R^n</m>. Write down a basis of <m>W</m>.</p>
<p>(iv) <m>W=\{(x_1,x_2,x_3,x_4)\in \R^4:x_1=x_3,x_2=x_4\}</m> is a 2-dimensional subspace of <m>\R^4</m>. Write dowm a basis of <m>W</m>.</p>

  </example>
</p>
<p>
  <alert>How to find basis of a subspace?</alert>
  </p>
  <p>
  Suppose  <m>W</m> is subspace spanned by a set of <m>k</m> vectors, say, 
  <m>v_1,\ldots,v_k</m> in <m>\R^n</m>. How to find a basis of <m>W</m>? 
  Note that <m>\dim{(W)}\leq k</m>. In order to find a basis of <m>W</m>, 
  we construct a matrix <m>A</m> whose rows are <m>v_1, \ldots, v_k</m>. 
  Find the reduced-row-echelon form  of <m>A</m>. 
  Then the non-zero rows in RREF(<m>A</m>) form a basis of <m>W</m>.  
  </p>
  
  <p>
  <example>
 <p>         Consider the set of vectors <m>v_1 =\left(1,-1,2,3,1,4\right)</m>, <m>v_2=\left(2,1,0,2,-3,1\right)</m>, <m>v_3=\left(-4,-5,4,0,11,5\right)</m>, <m>v_4=\left(-1,0,2,1,3,2\right)</m> and <m>v_5=\left(-2,-2,4,2,7,5\right)</m>. Let <m>W</m> be the linear span of <m>\{v_1,v_2,v_3,v_4,v_5\}</m>. Let us find a basis and hence the dimension of <m>W</m>. 
 </p>

    <p>
            We construct the matrix <m>A</m> whose rows are <m>\{v_1,v_2,v_3,v_4,v_5\}</m> and apply RREF.
     
                <me>
                RREF\left(\left[\begin{array}{rrrrrr}
                  1 \amp  -1 \amp  2 \amp  3 \amp  1 \amp  4 \\
                  2 \amp  1 \amp  0 \amp  2 \amp  -3 \amp  1 \\
                  -4 \amp  -5 \amp  4 \amp  0 \amp  11 \amp  5 \\
                  -1 \amp  0 \amp  2 \amp  1 \amp  3 \amp  2 \\
                  -2 \amp  -2 \amp  4 \amp  2 \amp  7 \amp  5
                \end{array}\right]\right)=\left[\begin{array}{rrrrrr}
                1 \amp  0 \amp  0 \amp  1 \amp  -\frac{5}{4} \amp  \frac{3}{4} \\
                0 \amp  1 \amp  0 \amp  0 \amp  -\frac{1}{2} \amp  -\frac{1}{2} \\
                0 \amp  0 \amp  1 \amp  1 \amp  \frac{7}{8} \amp  \frac{11}{8} \\
                0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0 \\
                0 \amp  0 \amp  0 \amp  0 \amp  0 \amp  0
                \end{array}\right]</me>

           Thus <m>W</m> has a basis consisting of three non zero rows of <m>RREF(A)</m>. That is, 
              <me>\beta = \left\{\left(1 , 0 , 0 , 1 , -\frac{5}{4} , \frac{3}{4}\right),
              \left(0 , 1 , 0 , 0 , -\frac{1}{2} , -\frac{1}{2}\right),
              \left(0 , 0 , 1 , 1 , \frac{7}{8} , \frac{11}{8}\right)\right\}</me> is basis of <m>W</m> and it is a 3 dimensional subspace of <m>\R^6</m>.
              Note that <m>W</m> is also the row space of <m>A</m>.       
              
              <p>
              Note that each column of <m>A</m> is a vector in <m>\R^5</m>. Let us find the column space of <m>A</m>. Thus to find the <m>{\rm col}(A)</m>, we take the transpose of <m>A</m> and apply the RREF. 
              </p>
<me>
RREF\left(\left[\begin{array}{rrrrr}
	1 \amp  2 \amp  -4 \amp  -1 \amp  -2 \\
	-1 \amp  1 \amp  -5 \amp  0 \amp  -2 \\
	2 \amp  0 \amp  4 \amp  2 \amp  4 \\
	3 \amp  2 \amp  0 \amp  1 \amp  2 \\
	1 \amp  -3 \amp  11 \amp  3 \amp  7 \\
	4 \amp  1 \amp  5 \amp  2 \amp  5
\end{array}\right]\right)=
\left[\begin{array}{rrrrr}
	1 \amp  0 \amp  2 \amp  0 \amp  1 \\
	0 \amp  1 \amp  -3 \amp  0 \amp  -1 \\
	0 \amp  0 \amp  0 \amp  1 \amp  1 \\
	0 \amp  0 \amp  0 \amp  0 \amp  0 \\
	0 \amp  0 \amp  0 \amp  0 \amp  0 \\
	0 \amp  0 \amp  0 \amp  0 \amp  0
\end{array}\right]
</me>

Thus the basis <m>\gamma</m> of  <m>{\rm col}(A)</m> consists of three non-zero rows of <m>RREF(A^T)</m>. Thus 
<me>
\gamma=\{(1,0,2,0,1),(0,1,-3,0,-1),(0,0,0,1,1)\}
</me>
is a basis of <m>{\rm col}(A)</m>. Notice that <m>\dim{({\rm col}(A))}=\dim{({\rm row}(A))}</m>.
        </p>
      </example>
    </p>

    <p>
      <definition xml:id="def-row-column-rank">
        <statement>
          <p>
            The <m>\dim{({\rm col}(A))}</m> is called the <alert>column rank</alert> of <m>A</m> and <m>\dim{({\rm row}(A))}</m> is called the <alert>row rank </alert>of <m>A</m>.	    
          </p>
        </statement>
      </definition>
    </p>
    <p>
      <theorem xml:id="thm-row-rank-col-rank">
        <statement>
          <p>
            The row rank and column rank of any matrix are same. This is called the rank of the matrix.
          </p>
        </statement>
      </theorem>
      
    </p>
<!--
<p>
  <figure xml:id="fig-sage-cubic">
    <caption>A cubic plotted by SageMath on
    <m>[-3,2]</m></caption>
    <image xml:id="sageplot-cubic" width="50%">
      <description>A cubic function on the interval
      [-3,2]</description>
  
  <sageplot>
  f(x) = (x-1)*(x+1)*(x-2)
  plot(f, (x, -3, 2), color='blue', thickness=3)
  </sageplot>
    </image>
  
  </figure>
</p>

<p>
  <image source="small-graph" width="20%">
    <description>A graph on five vertices.</description>
</image>
</p>

<p>
  <figure xml:id="fig-graph">
    <caption>A small graph (from <pubtitle>Applied
    Combinatorics</pubtitle> by Keller and
    Trotter)</caption>
    <image source="small-graph" width="20%"/>
  </figure>

</p>
-->
</section>
